{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Ta-Lib and yfinance librarys to the google colab\n",
    "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "!tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
    "%cd ta-lib\n",
    "!./configure --prefix=/usr\n",
    "!make\n",
    "!make install\n",
    "!pip install Ta-Lib\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import talib\n",
    "from talib import abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stocks list from initial_data.json\n",
    "os.chdir(\"..\")\n",
    "with open(\"./initial_data.json\") as f:\n",
    "    initial_data = json.loads(f.read())\n",
    "    \n",
    "# Create stocks_structs folder if not exist\n",
    "if not os.path.exists('stocks_structs'):\n",
    "    os.makedirs('stocks_structs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of abstract techlinical analysis function\n",
    "# Each of them will be calculated on the raw data and then be added to the df\n",
    "class Indicators:\n",
    "    @staticmethod\n",
    "    def create_indicators_file():\n",
    "        # Technical Indicator: [function, [tags]]\n",
    "        indicators_dict =  {'sma': [abstract.SMA, ['sma']],\n",
    "                            'ema': [abstract.EMA, ['ema']],\n",
    "                            'bbands': [abstract.BBANDS, ['upperband', 'middleband', 'lowerband']],\n",
    "                            'stoch': [abstract.STOCH, ['slowk', 'slowd']],\n",
    "                            'macd': [abstract.MACD, ['macd', 'macdsignal', 'macdhist']],\n",
    "                            'rsi': [abstract.RSI, ['rsi']],\n",
    "                            'adx': [abstract.ADX, ['adx']],\n",
    "                            'cci': [abstract.CCI, ['cci']],\n",
    "                            'aroon': [abstract.AROON, ['aroondown', 'aroonup']]\n",
    "                           }\n",
    "        return indicators_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock object struct, contains all the basic data on the stock\n",
    "class Stock:\n",
    "    def __init__(self, symbol, company, category, start):\n",
    "        self.sym = symbol\n",
    "        self.company = company\n",
    "        self.category = category\n",
    "        self.start = start\n",
    "        self.last_update = datetime.today().strftime('%Y-%m-%d')\n",
    "        self.classification = None\n",
    "        self.technical_indicators = None\n",
    "        self.raw_data = None\n",
    "        self.extended_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataDownloader:\n",
    "    # Dictionary of all the TA-lib indicators to calculate\n",
    "    indicators = Indicators.create_indicators_file()   \n",
    "    \n",
    "    @staticmethod\n",
    "    def call(stock):\n",
    "        # Call the query and analyze functions\n",
    "        # Return today's date as last_update, raw data from yf and extended df (yf + TaLib)\n",
    "        prices = DataDownloader.query(stock.sym)\n",
    "        analyzed = DataDownloader.analyze(prices, stock.start)\n",
    "        return datetime.today().strftime('%Y-%m-%d'), prices, analyzed\n",
    "        \n",
    "    @staticmethod\n",
    "    def query(symbol):\n",
    "        # Download the stock's dataset from yf\n",
    "        data = yf.download(symbol)\n",
    "        # Rename the columns names so TaLib can use it abstract functions\n",
    "        data.rename(columns={'Open':'open', 'High':'high',\n",
    "                             'Low':'low', 'Adj Close': 'close',\n",
    "                             'Volume':'volume'}, inplace=True)\n",
    "        # Remoce the Close column (there is already Adj Close)\n",
    "        data.drop(['Close'], axis = 1, inplace = True) \n",
    "        \n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def analyze(df, start):\n",
    "        # The extended df should contain only relevant data for training\n",
    "        # Remove row that are before the start date which is determineded in initial_data.json\n",
    "        extended_df = df.loc[df.index > start] \n",
    "        \n",
    "        # Calculate each technical indicator and add a column of it to the extended df \n",
    "        for indicator in DataDownloader.indicators.values():\n",
    "            new_data = pd.DataFrame(indicator[0](df))  # Calc the current indicator (new column)\n",
    "            \n",
    "            # Tag the new columns with the indicator name\n",
    "            columns = new_data.columns\n",
    "            new_cols = {col:tag for col, tag in zip(columns, indicator[1])} \n",
    "            new_data = new_data.rename(columns=new_cols)\n",
    "            \n",
    "            # Add the talib new column to the extended_df\n",
    "            extended_df = extended_df.join(new_data)\n",
    "\n",
    "        # Drop Na rows\n",
    "        extended_df = extended_df.dropna()\n",
    "\n",
    "        return extended_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    os.chdir(\"/content\")\n",
    "    stocks_list = []\n",
    "\n",
    "    # Initiate Stock object for each stock in initial_data.json add add it to the list\n",
    "    for key, value in initial_data.items():\n",
    "        print(f\"Create {key} Object\")\n",
    "        cur_stock = Stock(key, value[\"company_name\"], value[\"category\"], value[\"start_date\"])\n",
    "        stocks_list.append(cur_stock)\n",
    "\n",
    "    # Download the data for each stock and calculate technical indicators for the df\n",
    "    for stk in stocks_list:\n",
    "        print(f\"Download {stk.sym} Data\")\n",
    "        stk.last_update, stk.raw_data, stk.extended_df = DataDownloader.call(stk)\n",
    "\n",
    "        # Save the object as .stk file\n",
    "        with open(f'./stocks_structs/{stk.sym}.stk', 'wb') as handle:\n",
    "            pickle.dump(stk, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip all the .stk files in order to download it from colab to the local computer\n",
    "import shutil\n",
    "shutil.make_archive('stocks_structs', 'zip', 'stocks_structs')"
   ]
  }
 ]
}