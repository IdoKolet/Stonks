{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Softmax\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ml_models & ml_scalers folder if not exist\n",
    "if not os.path.exists('ml_models'):\n",
    "    os.makedirs('ml_models')\n",
    "\n",
    "if not os.path.exists('ml_scalers'):\n",
    "    os.makedirs('ml_scalers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load cleaned df ===> scale ===> add target ===> split to sliding window\n",
    "# ===> train (validation) + save model ===> test ===> predict tommorow\n",
    "class MLModel:\n",
    "    \"\"\"A class used for creating NN for each stock\n",
    "        Work flow: load cleaned df ==> scale ==> add target ==> \n",
    "        split to sliding window ==> train (validation) + save model ==> \n",
    "        test ==> predict tommorow\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol, df, model=None):\n",
    "        \"\"\"Constructor\n",
    "\n",
    "        Args:\n",
    "            symbol (str): Stock symbol\n",
    "            df (Pandas DF): data df\n",
    "            model (keras model, optional): If the is already a trained model us it\n",
    "        \"\"\"\n",
    "        self.symbol = symbol\n",
    "        self.df = df\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.scaler = None\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"Do all the preprocessing to the raw data (yahoo finance + talib) \n",
    "        \"\"\"\n",
    "        X = self.df.iloc[:-1]   # The input is all the data without today \n",
    "        y = self.one_hot_tags()   # One hot vector for the prediction [-,0,+]\n",
    "        \n",
    "        # Split to train and test\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Scale & to sliding windows train data\n",
    "        self.scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        X_train_scaled = pd.DataFrame(data=X_train_scaled, columns=self.X_train.columns, index=self.X_train.index)\n",
    "        self.X_train, self.y_train = self.to_windows(X_train_scaled, self.y_train)\n",
    "        \n",
    "        # Scale & to sliding windows test data\n",
    "        X_test_scaled = self.scaler.transform(self.X_test)\n",
    "        X_test_scaled = pd.DataFrame(data=X_test_scaled, columns=self.X_test.columns, index=self.X_test.index)\n",
    "        self.X_test, self.y_test = self.to_windows(X_test_scaled, self.y_test)\n",
    "        \n",
    "\n",
    "    def one_hot_tags(self):\n",
    "        \"\"\"Calculate the change in price, and tag the data with on hot.\n",
    "                   today - yestarday\n",
    "            dif = ----------------- * 100 %\n",
    "                    yestarday\n",
    "\n",
    "            +: [0,0,1]\n",
    "            0: [0,1,0]\n",
    "            -: [1,0,0]\n",
    "\n",
    "        Returns:\n",
    "            vector (np array): One hot encoding vector.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Calc the difference\n",
    "        differences = (self.df[\"close\"].iloc[1:].reset_index(drop=True) /\n",
    "                       self.df[\"close\"].iloc[:-1].reset_index(drop=True)) - 1 \n",
    "\n",
    "        # Init zeros np array\n",
    "        vector = np.zeros((differences.size,3))\n",
    "\n",
    "        # Set the \"one tag\" by the difference\n",
    "        for diff,i in zip(differences, range(differences.size)):\n",
    "            if diff > 0.02:\n",
    "                vector[i,2] = 1\n",
    "            elif diff < -0.02:\n",
    "                vector[i,0] = 1\n",
    "            else:\n",
    "                vector[i,1] = 1\n",
    "        \n",
    "        return vector\n",
    "\n",
    "    def to_windows(self, X, y, size=60):\n",
    "        \"\"\"Restruct the data as sliding window\n",
    "\n",
    "        Args:\n",
    "            X: data\n",
    "            y: tags\n",
    "            size (int, optional): window size. Defaults to 60.\n",
    "\n",
    "        Returns:\n",
    "            windows (np array): data restructes as windows\n",
    "            tags (np array): the compatiable tags to the windows\n",
    "        \"\"\"\n",
    "        windows = []\n",
    "        tags = y[size:]\n",
    "\n",
    "        # Build the windows strcture.\n",
    "        for i in range(size, len(X)):\n",
    "            windows.append(X[i-size:i])\n",
    "\n",
    "        # Convert to np array\n",
    "        windows, tags = np.array(windows), np.array(tags) \n",
    "        return windows, tags\n",
    "\n",
    "\n",
    "    def set_model(self):\n",
    "        \"\"\"Create NN with Dense, LSTM and softmax layers\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, return_sequences=True))\n",
    "        model.add(LSTM(50, return_sequences=False))\n",
    "        model.add(Dense(25))\n",
    "        model.add(Dense(3))     # 3 multi-class classification \n",
    "        model.add(Softmax())\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the NN\n",
    "        \"\"\"\n",
    "        self.model.fit(self.X_train, self.y_train, validation_split=0.2, \n",
    "                       shuffle=False, batch_size=1, epochs=12)\n",
    "\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"Save the trained model & transformed scaler\n",
    "        \"\"\"\n",
    "        self.model.save(f\"ml_models/{self.symbol}.keras\")\n",
    "        dump(self.scaler, open(f\"ml_scalers/{self.symbol}.sclr\", 'wb'))\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"Test the trained model on the test set and calc scores\n",
    "\n",
    "        Returns:\n",
    "            scores: percision, recall and f1\n",
    "        \"\"\"\n",
    "        pred = self.model.predict(self.X_test)\n",
    "        return precision_recall_fscore_support(np.argmax(self.y_test, axis=1), np.argmax(pred, axis=1), average='macro')\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Predict next day classification\n",
    "\n",
    "        Returns:\n",
    "            probabillity vector \n",
    "        \"\"\"\n",
    "        X = self.df.tail(60)\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        X_scaled = pd.DataFrame(data=X_scaled, columns=X.columns, index=X.index)\n",
    "        X_scaled = np.reshape(X_scaled.to_numpy(), (1, X_scaled.shape[0],  X_scaled.shape[1]))\n",
    "        return self.model.predict(X_scaled)\n",
    "\n",
    "\n",
    "    def activate(self):\n",
    "        \"\"\"Create model for stock from scratch\n",
    "        \"\"\"\n",
    "        print(f\"==========[ {self.symbol} ]==========\")\n",
    "        print(\"[+] Preprocessing...\")\n",
    "        self.preprocess()\n",
    "        print(\"[+] Initiating model...\")\n",
    "        self.set_model()\n",
    "        print(\"[+] Training...\")\n",
    "        self.train()\n",
    "        print(\"[+] Saving model & scaler...\")\n",
    "        self.save_model()\n",
    "        print(\"[+] Testing...\")\n",
    "        test_scores = self.test()\n",
    "        print(f\"Precision: {test_scores[0]}, Recall: {test_scores[1]}, F1: {test_scores[2]}\")\n",
    "        #print(self.predict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock object struct, contains all the basic data on the stock\n",
    "class Stock:\n",
    "    def __init__(self, symbol, company, category, start):\n",
    "        self.sym = symbol\n",
    "        self.company = company\n",
    "        self.category = category\n",
    "        self.start = start\n",
    "        self.last_update = datetime.today().strftime('%Y-%m-%d')\n",
    "        self.classification = None\n",
    "        self.technical_indicators = None\n",
    "        self.raw_data = None\n",
    "        self.extended_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_list = []\n",
    "for filename in os.listdir(\"stocks_structs\"):\n",
    "        stocks_list.append(pickle.load(open(f\"stocks_structs/{filename}\",\"rb\")))\n",
    "\n",
    "ml_models = [MLModel(stk.sym, stk.extended_df) for stk in stocks_list]\n",
    "\n",
    "for model in ml_models:\n",
    "    model.activate()"
   ]
  }
 ]
}